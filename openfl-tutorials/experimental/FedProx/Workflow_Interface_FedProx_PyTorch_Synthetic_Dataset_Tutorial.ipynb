{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Workflow Interface 104: MNIST with Fedcurv implementation\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/intel/openfl/blob/develop/openfl-tutorials/experimental/Workflow_Interface_104_MNIST_with_fedcurv.ipynb)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this OpenFL workflow interface tutorial, we'll learn how to implement FedProx and FedAvg algorithms using synthetic dataset."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Started"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we start by installing the necessary dependencies for the workflow interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install git+https://github.com/intel/openfl.git\n",
    "# !pip install -r requirements_workflow_interface.txt\n",
    "\n",
    "# Uncomment this if running in Google Colab\n",
    "#pip install -r https://raw.githubusercontent.com/intel/openfl/develop/openfl-tutorials/experimental/requirements_workflow_interface.txt\n",
    "#import os\n",
    "#os.environ[\"USERNAME\"] = \"colab\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch.nn import functional as F\n",
    "import torch as pt\n",
    "import numpy as np\n",
    "\n",
    "from openfl.interface.aggregation_functions.weighted_average import weighted_average as wa\n",
    "# from openfl.federated.task.runner_pt import _set_optimizer_state, _get_optimizer_state\n",
    "from openfl.experimental.interface import FLSpec, Aggregator, Collaborator\n",
    "from openfl.experimental.runtime import LocalRuntime\n",
    "from openfl.experimental.placement import aggregator, collaborator\n",
    "from openfl.utilities.optimizers.torch import FedProxOptimizer\n",
    "\n",
    "from collections import OrderedDict\n",
    "# from copy import deepcopy\n",
    "import math\n",
    "import random\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 100\n",
    "batch_size = 10\n",
    "learning_rate = 0.01\n",
    "log_interval = 1000\n",
    "weight_decay = 0.001\n",
    "E = 20\n",
    "NUM_COLLABORATORS = 30\n",
    "RANDOM_SEED = 10"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the following `mu` parameter to `0.0` to run FedAvg, and `1.0` to run FedProx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = 1.0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set seed in order to reproduce the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sets seed to reproduce the results\n",
    "def set_seed(seed):\n",
    "    pt.manual_seed(seed)\n",
    "    pt.cuda.manual_seed_all(seed)\n",
    "    pt.use_deterministic_algorithms(True)\n",
    "    pt.backends.cudnn.deterministic = True\n",
    "    pt.backends.cudnn.benchmark = False\n",
    "    pt.backends.cudnn.enabled = False\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "\n",
    "set_seed(RANDOM_SEED)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate Synthetic Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(labels, classes):\n",
    "    return np.eye(classes)[labels]\n",
    "\n",
    "\n",
    "def softmax(x):\n",
    "    ex = np.exp(x)\n",
    "    sum_ex = np.sum(np.exp(x))\n",
    "    return ex / sum_ex\n",
    "\n",
    "\n",
    "def generate_synthetic(alpha, beta, iid, num_collaborators, num_classes):\n",
    "    dimension = 60\n",
    "    NUM_CLASS = num_classes\n",
    "    NUM_USER = num_collaborators\n",
    "\n",
    "    samples_per_user = np.random.lognormal(4, 2, (NUM_USER)).astype(int) + 50\n",
    "    num_samples = np.sum(samples_per_user)\n",
    "\n",
    "    X_split = [[] for _ in range(NUM_USER)]\n",
    "    y_split = [[] for _ in range(NUM_USER)]\n",
    "\n",
    "    #### define some eprior ####\n",
    "    mean_W = np.random.normal(0, alpha, NUM_USER)\n",
    "    mean_b = mean_W\n",
    "    B = np.random.normal(0, beta, NUM_USER)\n",
    "    mean_x = np.zeros((NUM_USER, dimension))\n",
    "\n",
    "    diagonal = np.zeros(dimension)\n",
    "    for j in range(dimension):\n",
    "        diagonal[j] = np.power((j + 1), -1.2)\n",
    "    cov_x = np.diag(diagonal)\n",
    "\n",
    "    for i in range(NUM_USER):\n",
    "        if iid == 1:\n",
    "            mean_x[i] = np.ones(dimension) * B[i]  # all zeros\n",
    "        else:\n",
    "            mean_x[i] = np.random.normal(B[i], 1, dimension)\n",
    "\n",
    "    if iid == 1:\n",
    "        W_global = np.random.normal(0, 1, (dimension, NUM_CLASS))\n",
    "        b_global = np.random.normal(0, 1, NUM_CLASS)\n",
    "\n",
    "    for i in range(NUM_USER):\n",
    "\n",
    "        W = np.random.normal(mean_W[i], 1, (dimension, NUM_CLASS))\n",
    "        b = np.random.normal(mean_b[i], 1, NUM_CLASS)\n",
    "\n",
    "        if iid == 1:\n",
    "            W = W_global\n",
    "            b = b_global\n",
    "\n",
    "        xx = np.random.multivariate_normal(\n",
    "            mean_x[i], cov_x, samples_per_user[i])\n",
    "        yy = np.zeros(samples_per_user[i])\n",
    "\n",
    "        for j in range(samples_per_user[i]):\n",
    "            tmp = np.dot(xx[j], W) + b\n",
    "            yy[j] = np.argmax(softmax(tmp))\n",
    "\n",
    "        X_split[i] = xx.tolist()\n",
    "        y_split[i] = yy.tolist()\n",
    "\n",
    "    return X_split, y_split\n",
    "\n",
    "\n",
    "class SyntheticFederatedDataset:\n",
    "    def __init__(self, num_collaborators, batch_size=1, num_classes=10, **kwargs):\n",
    "        self.batch_size = batch_size\n",
    "        X, y = generate_synthetic(0.0, 0.0, 0, num_collaborators, num_classes)\n",
    "        X = [np.array([np.array(sample).astype(np.float32)\n",
    "                      for sample in col]) for col in X]\n",
    "        y = [np.array([np.array(one_hot(int(sample), num_classes))\n",
    "                      for sample in col]) for col in y]\n",
    "        self.X_train_all = np.array([col[:int(0.9 * len(col))] for col in X])\n",
    "        self.X_valid_all = np.array([col[int(0.9 * len(col)):] for col in X])\n",
    "        self.y_train_all = np.array([col[:int(0.9 * len(col))] for col in y])\n",
    "        self.y_valid_all = np.array([col[int(0.9 * len(col)):] for col in y])\n",
    "\n",
    "    def split(self, collaborators):\n",
    "        for i, collaborator in enumerate(collaborators):\n",
    "            collaborator.private_attributes = {\n",
    "                \"train_loader\":\n",
    "                    DataLoader(\n",
    "                        TensorDataset(\n",
    "                            pt.from_numpy(self.X_train_all[i]),\n",
    "                            pt.from_numpy(self.y_train_all[i])\n",
    "                        ), \n",
    "                        batch_size=batch_size, shuffle=True\n",
    "                    ),\n",
    "                \"test_loader\":\n",
    "                    DataLoader(\n",
    "                        TensorDataset(\n",
    "                            pt.from_numpy(self.X_valid_all[i]),\n",
    "                            pt.from_numpy(self.y_valid_all[i])\n",
    "                        ), \n",
    "                        batch_size=batch_size, shuffle=True\n",
    "                    )\n",
    "            }"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    \"\"\"\n",
    "    Model to train the dataset\n",
    "\n",
    "    Args:\n",
    "        None\n",
    "    \n",
    "    Returns:\n",
    "        model: class Net object\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        # Set RANDOM_STATE to reproduce same model\n",
    "        pt.set_rng_state(pt.manual_seed(RANDOM_SEED).get_state())\n",
    "        super(Net, self).__init__()\n",
    "        self.linear1 = nn.Linear(60, 100)\n",
    "        self.linear2 = nn.Linear(100, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear1(x)\n",
    "        x = self.linear2(x)\n",
    "        return x"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy(output, target):\n",
    "    \"\"\"\n",
    "    cross-entropy metric\n",
    "\n",
    "    Args:\n",
    "        output: model ouput,\n",
    "        target: target label\n",
    "\n",
    "    Returns:\n",
    "        crossentropy_loss: float\n",
    "    \"\"\"\n",
    "    return F.cross_entropy(output, pt.max(target, 1)[1])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Test method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(network, dataloader):\n",
    "    \"\"\"\n",
    "    Model test method\n",
    "\n",
    "    Args:\n",
    "        network: class Net object (model)\n",
    "        test_loader\n",
    "\n",
    "    Returns:\n",
    "        avg_test_accuracy\n",
    "        avg_test_loss\n",
    "    \"\"\"\n",
    "    network.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with pt.no_grad():\n",
    "        for data, target in dataloader:\n",
    "            output = network(data)\n",
    "            test_loss += cross_entropy(output, target).item()\n",
    "            tar = target.argmax(dim=1, keepdim=True)\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(tar).sum().cpu().numpy()\n",
    "    dataloader_size = len(dataloader.dataset)\n",
    "    test_loss /= dataloader_size\n",
    "    print('\\nTest set: Avg. loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, dataloader_size,\n",
    "        100. * correct / dataloader_size))\n",
    "    accuracy = float(correct / dataloader_size)\n",
    "    return accuracy, test_loss"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WeightedAverage function to take the weighted average of model, optimizer or loss, accuracy list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_average(tensors, weights):\n",
    "    \"\"\"\n",
    "    Take weighted average of models / optimizers / loss / accuracy\n",
    "\n",
    "    Args:\n",
    "        tensors: models state_dict list or optimizers state_dict list or loss list or accuracy list\n",
    "        weights: Weight as per to each model\n",
    "    \n",
    "    Returns:\n",
    "        dict / float: weighted average model / optimizzer / loss / accuracy\n",
    "    \"\"\"\n",
    "    # Check if passed list tensors elements are of what type\n",
    "    if type(tensors[0]) in (dict, OrderedDict):\n",
    "        optimizer = False\n",
    "        # If __opt_state_needed found then optimizer state dictionary is passed\n",
    "        if \"__opt_state_needed\" in tensors[0]:\n",
    "            optimizer = True\n",
    "            # Remove __opt_state_needed from all state dictionary in list\n",
    "            [tensor.pop(\"__opt_state_needed\") for tensor in tensors]\n",
    "        tmp_list = []\n",
    "        # Take keys in order to rebuild the state dictionary taking keys back up\n",
    "        input_state_dict_keys = tensors[0].keys()\n",
    "        for tensor in tensors:\n",
    "            # Append values of each state dictionary in list\n",
    "            # If type(value) is Tensor then it needs to be detached\n",
    "            tmp_list.append([value.detach() if type(value) is pt.Tensor else value for value in tensor.values()])\n",
    "        # Take weighted average of list of arrays\n",
    "        # new_params passed is weighted average of each array in tmp_list\n",
    "        new_params = wa(tmp_list, weights)\n",
    "        new_state = {}\n",
    "        # Take weighted average parameters and building a dictionary\n",
    "        [new_state.update({k:new_params[i]}) if optimizer else new_state.update({k:pt.from_numpy(new_params[i].numpy())}) \\\n",
    "            for i, k in enumerate(input_state_dict_keys)]\n",
    "        return new_state\n",
    "    else:\n",
    "        return wa(tensors, weights)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`FLSpec` – Defines the flow specification. User defined flows are subclasses of this."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we come to the flow definition. The OpenFL Workflow Interface adopts the conventions set by Metaflow, that every workflow begins with `start` and concludes with the `end` task. The aggregator begins with an optionally passed in model and optimizer. The aggregator begins the flow with the `start` task, where the list of collaborators is extracted from the runtime (`self.collaborators = self.runtime.collaborators`) and is then used as the list of participants to run the task listed in `self.next`, `aggregated_model_validation` where the aggregated model test beings and we compute, `train loss`, `train accuracy`, `test loss` and `test accuracy` for each collaborator. The tasks run is determined by the placement decorator that precedes each task definition (`@aggregator` or `@collaborator`). Once metricies are computed flow moves onto `gather_results` step which will execute on aggregator and collect all the computed results and take `weighted_average` of those metricies. The next step `inner_optimization` again will run on collaborator and train all collaborator models. Then flow will move to `join` step which will be executed on aggregator and in `join` model weighted average will be taken. Since we are using `FedProxOptimizer` we do not require to take weighted_average of optimizer in case of stateful optimizer (e.g. FedProxAdam) it will be required. Next step is `end`, it will increment the round number and flow will end.\n",
    "\n",
    "![flow graph](./graph.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FederatedFlow(FLSpec):\n",
    "\n",
    "    def __init__(self, model=None, optimizer=None, **kwargs):\n",
    "        super(FederatedFlow, self).__init__(**kwargs)\n",
    "        self.round_number = 0\n",
    "        if model is not None:\n",
    "            self.model = model\n",
    "            self.optimizer = optimizer\n",
    "        else:\n",
    "            self.model = Net()\n",
    "            self.optimizer = FedProxOptimizer(\n",
    "                self.model.parameters(), lr=learning_rate, mu=mu, weight_decay=weight_decay)\n",
    "\n",
    "    @aggregator\n",
    "    def start(self):\n",
    "        \"\"\"\n",
    "        Start of the flow\n",
    "        \"\"\"\n",
    "        self.collaborators = self.runtime.collaborators\n",
    "\n",
    "        self.next(self.aggregated_model_validation, foreach='collaborators')\n",
    "\n",
    "    @collaborator\n",
    "    def aggregated_model_validation(self):\n",
    "        \"\"\"\n",
    "        Validate aggregated model.\n",
    "        \"\"\"\n",
    "        print(\n",
    "            f'Performing aggregated model validation for collaborator {self.input}')\n",
    "        self.agg_validation_score, self.agg_validation_loss = inference(\n",
    "            self.model, self.test_loader)\n",
    "        print(f'{self.input} value of {self.agg_validation_score}')\n",
    "\n",
    "        # Compute Train Loss and Train Acc\n",
    "        self.training_accuracy, self.training_loss = inference(\n",
    "            self.model, self.train_loader)\n",
    "\n",
    "        self.train_ds = len(self.train_loader.dataset)\n",
    "        self.test_ds = len(self.test_loader.dataset)\n",
    "\n",
    "        self.next(self.gather_results)\n",
    "\n",
    "    @aggregator\n",
    "    def gather_results(self, inputs):\n",
    "        \"\"\"\n",
    "        Gather results of all collaborators\n",
    "        \"\"\"\n",
    "        # Calculate train_weights and test_weights\n",
    "        train_size = sum([input.train_ds for input in inputs])\n",
    "        self.train_weights = [input.train_ds / train_size for input in inputs]\n",
    "        test_size = sum([input.test_ds for input in inputs])\n",
    "        self.test_weights = [input.test_ds / test_size for input in inputs]\n",
    "\n",
    "        # Weighted average of training loss\n",
    "        self.training_loss = weighted_average(\n",
    "            [input_.training_loss for input_ in inputs], self.train_weights)\n",
    "        print(f'Average training loss = {self.training_loss}')\n",
    "\n",
    "        # Weighted average of training accuracy\n",
    "        self.training_accuracy = weighted_average(\n",
    "            [input_.training_accuracy for input_ in inputs], self.train_weights)\n",
    "\n",
    "        # Weighted average of aggregated model loss\n",
    "        self.agg_validation_loss = weighted_average(\n",
    "            [input_.agg_validation_loss for input_ in inputs], self.test_weights)\n",
    "\n",
    "        # Weighted average of aggregated model accuracy\n",
    "        self.aggregated_model_accuracy = weighted_average(\n",
    "            [input_.agg_validation_score for input_ in inputs], self.test_weights)\n",
    "        print(f'Average aggregated model validation values = {self.aggregated_model_accuracy}')\n",
    "\n",
    "        # Randomly select 1/3rd of collaborator out\n",
    "        self.selected_collaborator_indices = np.random.choice(range(len(self.collaborators)), \\\n",
    "            math.ceil(len(self.collaborators) / 3), replace=False)\n",
    "        self.selected_collaborators = [self.collaborators[idx] for idx in self.selected_collaborator_indices]\n",
    "\n",
    "        self.next(self.inner_optimization, foreach=\"collaborators\")\n",
    "\n",
    "    @collaborator\n",
    "    def inner_optimization(self):\n",
    "        \"\"\"\n",
    "        Collaborators Training\n",
    "        \"\"\"\n",
    "        # Rebuild optimizer to pass the aggregated model parameters to optimizer\n",
    "        self.optimizer = FedProxOptimizer(\n",
    "            self.model.parameters(), lr=learning_rate, mu=mu, weight_decay=weight_decay)\n",
    "\n",
    "        # Set current model parameters to optimizer after training the same parameters will become old\n",
    "        self.optimizer.set_old_weights([p.clone().detach() for p in self.model.parameters()])\n",
    "\n",
    "        train_loss = []\n",
    "        correct = 0\n",
    "        for epoch in range(E):\n",
    "            for batch_idx, (data, target) in enumerate(self.train_loader):\n",
    "                self.optimizer.zero_grad()\n",
    "                output = self.model(data)\n",
    "                loss = cross_entropy(output, target)\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                pred = output.argmax(dim=1, keepdim=True)\n",
    "                tar = target.argmax(dim=1, keepdim=True)\n",
    "                correct += pred.eq(tar).sum().cpu().numpy()\n",
    "                train_loss.append(loss.item())\n",
    "                if batch_idx % log_interval == 0:\n",
    "                    print('Inner Optimization Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                        epoch, batch_idx * len(data), len(data),\n",
    "                        100. * batch_idx * len(data) / len(data), loss.item()))\n",
    "\n",
    "            inner_opt_training_accuracy = float(correct / len(self.train_loader.dataset))\n",
    "            inner_opt_training_loss = np.mean(train_loss)\n",
    "            print (f\"Inner Optimization Training Loss: {inner_opt_training_loss}, and Accuracy: {inner_opt_training_accuracy}\")\n",
    "\n",
    "        self.next(self.join)\n",
    "    \n",
    "    @aggregator\n",
    "    def join(self, inputs):\n",
    "        \"\"\"\n",
    "        Aggregate Model.\n",
    "        \"\"\"\n",
    "        self.loss_and_acc = {\n",
    "            input_.input: {\"Train Loss\": [], \"Agg Train Accuracy\": []}\n",
    "            for input_ in inputs\n",
    "        }\n",
    "        self.loss_and_acc.update({\"Aggregated\": {\"Test Loss\": [], \"Test Accuracy\": []}})\n",
    "\n",
    "        for input_ in inputs:\n",
    "            self.loss_and_acc[input_.input][\"Train Loss\"].append(input_.training_loss)\n",
    "            self.loss_and_acc[input_.input][\"Agg Train Accuracy\"].append(input_.training_accuracy)\n",
    "        self.loss_and_acc[\"Aggregated\"][\"Test Loss\"].append(self.agg_validation_loss)\n",
    "        self.loss_and_acc[\"Aggregated\"][\"Test Accuracy\"].append(self.aggregated_model_accuracy)\n",
    "\n",
    "        input_weights = []\n",
    "        t_weights = []\n",
    "        for c in self.selected_collaborator_indices:\n",
    "            input_weights.append(inputs[c].model.state_dict())\n",
    "            t_weights.append(self.train_weights[c])\n",
    "\n",
    "        avg_model_dict = weighted_average(input_weights, t_weights)\n",
    "        self.model.load_state_dict(avg_model_dict)\n",
    "\n",
    "        self.optimizer = [input_.optimizer for input_ in inputs][0]\n",
    "\n",
    "        self.next(self.end)\n",
    "\n",
    "    @aggregator\n",
    "    def end(self):\n",
    "        \"\"\"\n",
    "        This is the 'end' step. All flows must have an 'end' step, which is the\n",
    "        last step in the flow.\n",
    "        \"\"\"\n",
    "        self.round_number += 1\n",
    "        print('This is end of the flow')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `Runtime` – Defines where the flow runs, infrastructure for task transitions (how information gets sent). The `LocalRuntime` runs the flow on a single node.\n",
    "- `aggregator/collaborator` – placement decorators that define where the task will be assigned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup aggregator\n",
    "aggregator = Aggregator()\n",
    "aggregator.private_attributes = {}\n",
    "\n",
    "# Setup collaborators with private attributes\n",
    "collaborator_names = [f\"col{i}\" for i in range(NUM_COLLABORATORS)]\n",
    "\n",
    "collaborators = [Collaborator(name=name) for name in collaborator_names]\n",
    "\n",
    "synthetic_federated_dataset = SyntheticFederatedDataset(\n",
    "    batch_size=batch_size, num_classes=10, num_collaborators=len(collaborators), seed=RANDOM_SEED)\n",
    "synthetic_federated_dataset.split(collaborators)\n",
    "\n",
    "local_runtime = LocalRuntime(\n",
    "    aggregator=aggregator, collaborators=collaborators, backend=\"single_process\")\n",
    "\n",
    "model = None\n",
    "best_model = None\n",
    "optimizer = None\n",
    "top_model_accuracy = 0\n",
    "loss_and_acc = {}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Executing FedProx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flflow = FederatedFlow(model, optimizer, checkpoint=True)\n",
    "flflow.runtime = local_runtime\n",
    "for i in range(n_epochs):\n",
    "    print(f'Starting round {i}...')\n",
    "    flflow.run()\n",
    "    for k, v in flflow.loss_and_acc.items():\n",
    "        if k == \"Aggregated\":\n",
    "            if \"FedProx\" not in loss_and_acc:\n",
    "                loss_and_acc[\"FedProx\"] = {\"Test Loss\": [], \"Test Accuracy\": []}\n",
    "            loss_and_acc[\"FedProx\"][\"Test Loss\"].append(*v[\"Test Loss\"])\n",
    "            loss_and_acc[\"FedProx\"][\"Test Accuracy\"].append(*v[\"Test Accuracy\"])\n",
    "\n",
    "    model = flflow.model\n",
    "    optimizer = flflow.optimizer\n",
    "    aggregated_model_accuracy = flflow.aggregated_model_accuracy\n",
    "    if aggregated_model_accuracy > top_model_accuracy:\n",
    "        print(f'Accuracy improved to {aggregated_model_accuracy} '\n",
    "                + f'for round {i}')\n",
    "        top_model_accuracy = aggregated_model_accuracy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting `mu = 0.0` will produce the FedAvg results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = 0.0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execting FedAvg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flflow = FederatedFlow(model, optimizer, checkpoint=True)\n",
    "flflow.runtime = local_runtime\n",
    "for i in range(n_epochs):\n",
    "    print(f'Starting round {i}...')\n",
    "    flflow.run()\n",
    "    for k, v in flflow.loss_and_acc.items():\n",
    "        if k == \"Aggregated\":\n",
    "            if \"FedAvg\" not in loss_and_acc:\n",
    "                loss_and_acc[\"FedAvg\"] = {\"Test Loss\": [], \"Test Accuracy\": []}\n",
    "            loss_and_acc[\"FedAvg\"][\"Test Loss\"].append(*v[\"Test Loss\"])\n",
    "            loss_and_acc[\"FedAvg\"][\"Test Accuracy\"].append(*v[\"Test Accuracy\"])\n",
    "\n",
    "    model = flflow.model\n",
    "    optimizer = flflow.optimizer\n",
    "    aggregated_model_accuracy = flflow.aggregated_model_accuracy\n",
    "    if aggregated_model_accuracy > top_model_accuracy:\n",
    "        print(f'Accuracy improved to {aggregated_model_accuracy} '\n",
    "                + f'for round {i}')\n",
    "        top_model_accuracy = aggregated_model_accuracy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting FedProx vs FedAvg graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "fedprox_loss = loss_and_acc[\"FedProx\"][\"Test Loss\"]\n",
    "fedavg_loss = loss_and_acc[\"FedAvg\"][\"Test Loss\"]\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(fedprox_loss)\n",
    "plt.plot(fedavg_loss)\n",
    "plt.legend([\"FedProx Loss\", \"FedAvg Loss\"])\n",
    "plt.title(\"FedProx vs FedAvg Loss\")\n",
    "\n",
    "fedprox_accuracy = loss_and_acc[\"FedProx\"][\"Test Accuracy\"]\n",
    "fedavg_accuracy = loss_and_acc[\"FedAvg\"][\"Test Accuracy\"]\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(fedprox_accuracy)\n",
    "plt.plot(fedavg_accuracy)\n",
    "plt.legend([\"FedProx Accuracy\", \"FedAvg Accuracy\"])\n",
    "plt.title(\"FedProx vs FedAvg Accuracy\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_28th_dec_openfl_experimental",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9f02ab5afaa1e381f2c0e5352e961c403cc83391c217d954e66a33de9be28988"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
